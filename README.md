# Congreso Insights

**Congreso Insights** es una herramienta modular que permite automatizar la descarga, anÃ¡lisis y visualizaciÃ³n de datos parlamentarios del Congreso de los Diputados de EspaÃ±a.

---

## ğŸ“ Estructura del proyecto

```text
congreso_insights/
â”‚
â”œâ”€â”€ main.py                         # Script principal de ejecuciÃ³n
â”œâ”€â”€ README.md                       # DocumentaciÃ³n del proyecto
â”œâ”€â”€ requirements.txt                # Dependencias necesarias
â”œâ”€â”€ .gitignore                      # Archivos excluidos del control de versiones
â”œâ”€â”€ diputados.csv                   # Salida: datos de diputados y suplencias
â”œâ”€â”€ grupos.csv                      # Salida: composiciÃ³n de grupos parlamentarios
â”œâ”€â”€ diarios_html/                   # HTMLs descargados de los diarios del Congreso
â”‚
â”œâ”€â”€ analysis/                       # MÃ³dulo de anÃ¡lisis de discursos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ graph_builder.py            # ConstrucciÃ³n y anÃ¡lisis de grafos en Neo4j
â”‚
â”œâ”€â”€ scraping/                       # MÃ³dulo de scraping web
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ congreso_scraper.py         # Scraper de diarios de sesiones (plenos)
â”‚   â”œâ”€â”€ scraper_diputados.py        # Scraper del listado de diputados
â”‚   â”œâ”€â”€ scraper_grupos.py           # Scraper de composiciÃ³n de grupos parlamentarios
â”‚   â”œâ”€â”€ enriquecedor_suplencias.py  # ObtenciÃ³n de fechas y relaciones de suplencias
â”‚   â””â”€â”€ utils/                      # Utilidades compartidas para Selenium
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ selenium_utils.py       # InicializaciÃ³n y funciones auxiliares
â”‚
â”œâ”€â”€ test/                           # Tests unitarios del proyecto
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_congreso_scraper.py    # Tests del scraping de diarios
â”‚   â”œâ”€â”€ test_graph_builder.py       # Tests del anÃ¡lisis en Neo4j
â”‚   â””â”€â”€ test_output/                # Carpeta temporal de salida de tests
```

---

## ğŸ§© Componentes

- `scraping/`: Descarga automatizada de datos desde el portal del Congreso.
- `analysis/`: AnÃ¡lisis semÃ¡ntico y de redes sobre discursos usando Neo4j y GDS.
- `test/`: ValidaciÃ³n del correcto funcionamiento de los scrapers y anÃ¡lisis.
- `diarios_html/`: Carpeta donde se almacenan los HTML de sesiones plenarias.
- `diputados.csv` y `grupos.csv`: Resultados estructurados de scraping y anÃ¡lisis de parlamentarios.

---

## â–¶ï¸ Uso

```bash
python main.py (opciÃ³n)
```

Por ejemplo:

```bash
python main.py analizar
```

---

## ğŸ§° Requisitos

- Python `3.8+`
- ChromeDriver (compatible con tu versiÃ³n de Chrome)
- Neo4j (4.x o superior con GDS instalado)

---

## ğŸ“¦ InstalaciÃ³n

```bash
pip install -r requirements.txt
```
